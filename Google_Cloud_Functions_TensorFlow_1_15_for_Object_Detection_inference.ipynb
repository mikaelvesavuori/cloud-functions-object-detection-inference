{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Google Cloud Functions: TensorFlow 1.15 for Object Detection inference.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNnpqbWBYHtK2Dlk4dBkhbq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mikaelvesavuori/cloud-functions-object-detection-inference/blob/master/Google_Cloud_Functions_TensorFlow_1_15_for_Object_Detection_inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYKhxWUgr8bp",
        "colab_type": "text"
      },
      "source": [
        "# Google Cloud Functions: TensorFlow 1.15 for Object Detection inference\n",
        "\n",
        "This sample function is a fairly minimal implementation of how you can do object detection inference in a Google Cloud Function. It will not assist in any of the training steps, for which I recommend Colaboratory or some other dedicated environment.\n",
        "\n",
        "**Note**:\n",
        "- This notebook should be able to \"emulate\" the experience of the function, but you will likely need to do a bit of copy-paste back-and-forth to ensure your real Cloud Function works as intended, as you make any changes of your own.\n",
        "- There are very small differences between using this in Colab and in a real function. For example: In Colab you'll need to run the first two cells to prep the environments. Those two cells should not be part of your Cloud Function source code!\n",
        "- This implementation is not optimized for container reuse and performance\n",
        "- Images will be loaded from source as a file, NOT as Base64 (in which case you probably need to modify the below code, as well as use a model that takes in `encoded_image_string_tensor`)\n",
        "\n",
        "## Need to (re)train an object detection model?\n",
        "\n",
        "I have a notebook at https://colab.research.google.com/drive/1FaMfcgskz84VWPb3fAAPQczFTND-zbBl that might help you.\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "- Google Cloud Platform account\n",
        "- Ready-to-go model (frozen inference graph; `image_tensor` input assumed)\n",
        "- `label_map.pbtxt` with your labels\n",
        "\n",
        "## Function specifications\n",
        "\n",
        "- Python 3.7 runtime (Guess it works fine in Python 3.8 as well)\n",
        "- 2 GB RAM should give a bit of a boost to the inference speed\n",
        "- Set the following content in your `requirements.txt` file.\n",
        "\n",
        "```\n",
        "tensorflow==1.15.2\n",
        "google-cloud-storage==1.28.1\n",
        "Pillow==7.1.2\n",
        "```\n",
        "\n",
        "## References\n",
        "\n",
        "These are some of the resources I've learned from and re-adapted below:\n",
        "\n",
        "- https://cloud.google.com/blog/products/ai-machine-learning/how-to-serve-deep-learning-models-using-tensorflow-2-0-with-cloud-functions\n",
        "- https://colab.research.google.com/github/tensorflow/models/blob/master/research/object_detection/object_detection_tutorial.ipynb\n",
        "\n",
        "Thanks also to various answers on Stack Overflow that I could not find in my history... :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-6Dadzfw8sG",
        "colab_type": "text"
      },
      "source": [
        "## Colab-only prep steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFemfdqKtNe7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Only run this prep step if \"emulating\" inside of Colaboratory!\n",
        "# In the real function, you will use the download_blob() function to fetch assets\n",
        "\n",
        "%cd /content/\n",
        "\n",
        "! curl -O -L https://materials"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UddFhdHKjmaB",
        "colab_type": "code",
        "outputId": "5368477f-97c5-4819-b48c-8d5aee9c6e0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Only run this prep step if \"emulating\" inside of Colaboratory!\n",
        "# In the real function, you will set the TensorFlow requirement to be \"1.15.2\"\n",
        "\n",
        "# Force TF v1 since this is the one that actually works for object detection (as of April 2020)\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMI6bxjIywLJ",
        "colab_type": "text"
      },
      "source": [
        "## Cloud Functions + Colab\n",
        "\n",
        "Look out for any comments on changes required between CF and Colab!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeBn3i5cr4nY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import json\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Use \"/content/\" when in Colaboratory\n",
        "# Use \"/tmp/\" when in actual Cloud Function environment\n",
        "BUCKET_NAME = 'my-ml-models'\n",
        "PATH_TO_MODEL = '/content/frozen_inference_graph_image_tensor.pb'\n",
        "PATH_TO_LABELS = '/content/label_map.pbtxt'\n",
        "PATH_TO_IMAGE = '/content/test.jpeg'\n",
        "\n",
        "# Have a local array/list copy of classes in \"label_map.pbtxt\", so we can easily pull and match classes and avoid additional file operations.\n",
        "# This MUST map to the same pattern and ordering as the \"label_map.pbtxt\" file!\n",
        "model_classes = [\n",
        "  'some-class-1',\n",
        "  'some-class-2',\n",
        "  'some-class-3',\n",
        "  'some-class-4'\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgR7yHndjg85",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def download_blob(bucket_name, source_blob_name, destination_file_name):\n",
        "    storage_client = storage.Client()\n",
        "    bucket = storage_client.get_bucket(bucket_name)\n",
        "    blob = bucket.blob(source_blob_name)\n",
        "\n",
        "    blob.download_to_filename(destination_file_name)\n",
        "\n",
        "    print('Blob {} downloaded to {}.'.format(\n",
        "        source_blob_name,\n",
        "        destination_file_name))\n",
        "\n",
        "\n",
        "def load_image_into_numpy_array(image):\n",
        "    (im_width, im_height) = image.size\n",
        "    return np.array(image.getdata()).reshape(\n",
        "        (im_height, im_width, 3)).astype(np.uint8)\n",
        "\n",
        "\n",
        "def run_inference_for_single_image(image, graph):\n",
        "    with graph.as_default():\n",
        "        with tf.Session() as sess:\n",
        "            ops = tf.get_default_graph().get_operations()\n",
        "            all_tensor_names = {\n",
        "                output.name for op in ops for output in op.outputs}\n",
        "            tensor_dict = {}\n",
        "            for key in [\n",
        "                'num_detections', 'detection_boxes', 'detection_scores',\n",
        "                'detection_classes', 'detection_masks'\n",
        "            ]:\n",
        "                tensor_name = key + ':0'\n",
        "                if tensor_name in all_tensor_names:\n",
        "                    tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
        "                        tensor_name)\n",
        "            if 'detection_masks' in tensor_dict:\n",
        "                detection_boxes = tf.squeeze(\n",
        "                    tensor_dict['detection_boxes'], [0])\n",
        "                detection_masks = tf.squeeze(\n",
        "                    tensor_dict['detection_masks'], [0])\n",
        "                real_num_detection = tf.cast(\n",
        "                    tensor_dict['num_detections'][0], tf.int32)\n",
        "                detection_boxes = tf.slice(detection_boxes, [0, 0], [\n",
        "                                           real_num_detection, -1])\n",
        "                detection_masks = tf.slice(detection_masks, [0, 0, 0], [\n",
        "                                           real_num_detection, -1, -1])\n",
        "                detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
        "                    detection_masks, detection_boxes, image.shape[0], image.shape[1])\n",
        "                detection_masks_reframed = tf.cast(\n",
        "                    tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
        "                tensor_dict['detection_masks'] = tf.expand_dims(\n",
        "                    detection_masks_reframed, 0)\n",
        "            image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
        "\n",
        "            output_dict = sess.run(tensor_dict,\n",
        "                                   feed_dict={image_tensor: np.expand_dims(image, 0)})\n",
        "\n",
        "            output_dict['num_detections'] = int(\n",
        "                output_dict['num_detections'][0])\n",
        "            output_dict['detection_classes'] = output_dict[\n",
        "                'detection_classes'][0].astype(np.uint8)\n",
        "            output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
        "            output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
        "            if 'detection_masks' in output_dict:\n",
        "                output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
        "    return output_dict\n",
        "\n",
        "\n",
        "def handler(request):\n",
        "    image_url = ''\n",
        "\n",
        "    request_json = request.get_json(silent=True)\n",
        "    request_args = request.args\n",
        "\n",
        "    if request_json and 'image_url' in request_json:\n",
        "        image_url = request_json['image_url']\n",
        "    elif request_args and 'image_url' in request_args:\n",
        "        request_json = request_args['image_url']\n",
        "\n",
        "    print('image_url:', image_url)\n",
        "\n",
        "    \"\"\"\n",
        "    The function will need to grab the model and labels first.\n",
        "    \n",
        "    Since your Colab \"emulation\" already has these downloaded from a previous step,\n",
        "    you only need the below for the real Cloud Functions code.\n",
        "    \"\"\"\n",
        "\n",
        "    # download_blob(BUCKET_NAME, 'tf-cloud-functions/test.jpeg',\n",
        "    #              '/tmp/test.jpeg')\n",
        "    # download_blob(BUCKET_NAME, 'tf-cloud-functions/frozen_inference_graph_image_tensor.pb',\n",
        "    #              '/tmp/frozen_inference_graph_image_tensor.pb')\n",
        "    # download_blob(BUCKET_NAME, 'tf-cloud-functions/label_map.pbtxt',\n",
        "    #              '/tmp/label_map.pbtxt')\n",
        "\n",
        "    results = []\n",
        "\n",
        "    detection_graph = tf.Graph()\n",
        "    with detection_graph.as_default():\n",
        "        od_graph_def = tf.GraphDef()\n",
        "        with tf.gfile.GFile(PATH_TO_MODEL, 'rb') as fid:\n",
        "            serialized_graph = fid.read()\n",
        "            od_graph_def.ParseFromString(serialized_graph)\n",
        "            tf.import_graph_def(od_graph_def, name='')\n",
        "\n",
        "    with detection_graph.as_default():\n",
        "        with tf.Session(graph=detection_graph) as sess:\n",
        "            image = Image.open(PATH_TO_IMAGE)\n",
        "            image_np = load_image_into_numpy_array(image)\n",
        "            image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "            image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
        "            boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
        "            scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
        "            classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
        "            num_detections = detection_graph.get_tensor_by_name(\n",
        "                'num_detections:0')\n",
        "\n",
        "            output_dict = run_inference_for_single_image(\n",
        "                image_np, detection_graph)\n",
        "\n",
        "            (boxes, scores, classes, num_detections) = sess.run(\n",
        "                [boxes, scores, classes, num_detections],\n",
        "                feed_dict={image_tensor: image_np_expanded})\n",
        "\n",
        "            boxes = output_dict['detection_boxes']\n",
        "            max_boxes_to_draw = boxes.shape[0]\n",
        "            scores = output_dict['detection_scores']\n",
        "\n",
        "            # Set your scoring threshold here (.7 = 70%)\n",
        "            min_score_thresh = .7\n",
        "\n",
        "            for i in range(min(max_boxes_to_draw, boxes.shape[0])):\n",
        "                if scores is None or scores[i] > min_score_thresh:\n",
        "                    _class_int = int(classes[0][i] - 1)\n",
        "                    print('Class:', model_classes[_class_int])\n",
        "                    print('Score:', scores[i])\n",
        "                    print('Box:', boxes[i])\n",
        "\n",
        "                    _result = {}\n",
        "                    _result['class'] = model_classes[_class_int]\n",
        "                    _result[\"score\"] = json.dumps(str(scores[i]))\n",
        "                    _result[\"box\"] = json.dumps(str(boxes[i]))\n",
        "                    results.append(_result)\n",
        "\n",
        "    # Return JSON as per any normal HTTP response\n",
        "    stringified_response = json.dumps(results)\n",
        "    print(stringified_response)\n",
        "\n",
        "    topic = TOPIC_PATH\n",
        "\n",
        "    data = stringified_response\n",
        "    data = data.encode(\"utf-8\")\n",
        "\n",
        "    encoded_file_name = file_name\n",
        "    encoded_file_name = file_name.encode(\"utf-8\")\n",
        "\n",
        "    return stringified_response"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXeZ5pIr1diq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Explicitly run the handler() function in Colab\n",
        "# No need for this in an actual Cloud Functions environment!\n",
        "handler(None);"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}